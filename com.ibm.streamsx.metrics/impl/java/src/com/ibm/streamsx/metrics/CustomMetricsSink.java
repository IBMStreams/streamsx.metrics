/* Generated by Streams Studio: November 29, 2016 at 3:22:39 PM EST */
package com.ibm.streamsx.metrics;


import java.net.InetAddress;
import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.concurrent.TimeUnit;

import org.apache.log4j.Logger;
import org.elasticsearch.action.index.IndexResponse;
import org.elasticsearch.client.transport.TransportClient;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.common.transport.InetSocketTransportAddress;
import org.elasticsearch.common.xcontent.XContentBuilder;
import org.elasticsearch.common.xcontent.XContentFactory;
import org.elasticsearch.transport.client.PreBuiltTransportClient;
import org.influxdb.InfluxDB;
import org.influxdb.InfluxDBFactory;
import org.influxdb.InfluxDB.ConsistencyLevel;
import org.influxdb.dto.BatchPoints;
import org.influxdb.dto.Point;

import com.ibm.streams.operator.AbstractOperator;
import com.ibm.streams.operator.OperatorContext;
import com.ibm.streams.operator.StreamingData.Punctuation;
import com.ibm.streams.operator.StreamingInput;
import com.ibm.streams.operator.Tuple;
import com.ibm.streams.operator.model.InputPortSet;
import com.ibm.streams.operator.model.InputPortSet.WindowMode;
import com.ibm.streams.operator.model.InputPortSet.WindowPunctuationInputMode;
import com.ibm.streams.operator.model.InputPorts;
import com.ibm.streams.operator.model.Libraries;
import com.ibm.streams.operator.model.Parameter;
import com.ibm.streams.operator.model.PrimitiveOperator;

@PrimitiveOperator(name="CustomMetricsSink", namespace="com.ibm.streamsx.metrics",
description="Java Operator CustomMetricsSink")
@InputPorts({@InputPortSet(description="Port that ingests tuples", cardinality=1, optional=false, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious), @InputPortSet(description="Optional input ports", optional=true, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious)})
@Libraries({
	// As described here:
	// http://www.ibm.com/support/knowledgecenter/en/SSCRJU_4.2.0/com.ibm.streams.dev.doc/doc/jmxapi-start.html
	// Environment variables (@...@) are evaluated during compile-time and must
	// be identical in the run-time environment.
	"@STREAMS_INSTALL@/lib/com.ibm.streams.management.jmxmp.jar",
	"@STREAMS_INSTALL@/lib/com.ibm.streams.management.mx.jar",
	"@STREAMS_INSTALL@/ext/lib/jmxremote_optional.jar",
	"opt/downloaded/*"
	})
public class CustomMetricsSink extends AbstractOperator {
	
	// Parameter definition.
	private static final String ATTRIBUTE_NAMES = 
			"Specifies the attributes values to output to databases.";

	String[] attributeList = null;
	
	@Parameter(
			optional=false,
			description=CustomMetricsSink.ATTRIBUTE_NAMES
			)
	public void set_attribute_names(String listString) {
		attributeList = listString.split(",");
	}
	
	// InfluxDB variables.
	InfluxDB influxDB = null;
	String dbName = null;
	BatchPoints batchPoints = null;
	String jobName = null;
	
	// ElasticSearch variables.
	TransportClient client = null;
	XContentBuilder builder = null;
	IndexResponse response = null;
	
	@SuppressWarnings("resource")
	@Override
	public synchronized void initialize(OperatorContext context)
			throws Exception {
		super.initialize(context);
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " initializing in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
	
        // Connect to InfluxDB server.
        influxDB = InfluxDBFactory.connect("http://localhost:8086", "admin", "admin");
    	dbName = "streamsDb";
    	influxDB.createDatabase(dbName);
        
    	// Initialize object to contain batch of points.
    	batchPoints = BatchPoints
	    	.database(dbName)
    		.tag("async", "true")
            .retentionPolicy("autogen")
            .consistency(ConsistencyLevel.ALL)
            .build();
    	
    	// Connect to ElasticSearch server.
		client = new PreBuiltTransportClient(Settings.EMPTY).addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName("localhost"), 9300));
	}

    @Override
    public synchronized void allPortsReady() throws Exception {
        OperatorContext context = getOperatorContext();
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " all ports are ready in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
    }

    @Override
    public void process(StreamingInput<Tuple> stream, Tuple tuple)
            throws Exception {
    	
    	// Check if specified attributes exist.
    	for(int i = 0; i < attributeList.length; i++) {
    		if(tuple.getString(attributeList[i]) != null) {
    			
    			// Create InfluxDB point to output.
    			Point point = Point.measurement("customMetrics")
    		            .time(System.currentTimeMillis(), TimeUnit.MILLISECONDS)
    		            .addField(attributeList[i], tuple.getLong(attributeList[i]))
    		            .build();
    		        
		        // Store in batch until window marker is received.
		        batchPoints.point(point);
    		        
    		    // Create ElasticSearch JSON to output.
		        DateFormat df = new SimpleDateFormat("yyyy'-'MM'-'dd'T'HH':'mm':'ss.SSSZZ");
		        
		        builder = XContentFactory.jsonBuilder()
		        		.startObject()
			        		.field("lastTimeRetrieved", df.format(new Date(System.currentTimeMillis())))
		        			.field(attributeList[i], Integer.parseInt(tuple.getString(attributeList[i])))
		        		.endObject();
    		}
    	}
    	
    	// Output metrics to InfluxDB.
    	if(batchPoints != null) {
    		influxDB.write(batchPoints);
    	}
        
        // Output metrics to ElasticSearch.
    	if(builder != null) {
    		response = client.prepareIndex("streamsdb", "custommetrics")
            	.setSource(builder)
            	.get();
    	}
    }
    
    @Override
    public void processPunctuation(StreamingInput<Tuple> stream,
    		Punctuation mark) throws Exception {
    }

    @Override
    public synchronized void shutdown() throws Exception {
        OperatorContext context = getOperatorContext();
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " shutting down in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
        
        // Close connection to InfluxDB server.
//      influxDB.close();

        // Close connection to ElasticSearch server.
        client.close();
        
        super.shutdown();
    }
    
}
