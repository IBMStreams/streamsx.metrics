/* Generated by Streams Studio: October 18, 2016 at 3:12:58 PM GMT+2 */
package com.ibm.streamsx.metrics;


import java.math.BigInteger;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Set;

import javax.management.JMX;
import javax.management.remote.JMXConnectorFactory;
import javax.management.remote.JMXServiceURL;

import org.apache.log4j.Logger;

import com.ibm.streams.management.Metric;
import com.ibm.streams.management.ObjectNameBuilder;
import com.ibm.streams.management.instance.InstanceMXBean;
import com.ibm.streams.management.job.JobMXBean;
import com.ibm.streams.management.job.PeMXBean;
import com.ibm.streams.operator.AbstractOperator;
import com.ibm.streams.operator.OperatorContext;
import com.ibm.streams.operator.OutputTuple;
import com.ibm.streams.operator.StreamingData.Punctuation;
import com.ibm.streams.operator.StreamingOutput;
import com.ibm.streams.operator.model.Libraries;
import com.ibm.streams.operator.model.OutputPortSet;
import com.ibm.streams.operator.model.OutputPortSet.WindowPunctuationOutputMode;
import com.ibm.streams.operator.model.OutputPorts;
import com.ibm.streams.operator.model.Parameter;
import com.ibm.streams.operator.model.PrimitiveOperator;
import com.ibm.streamsx.metrics.internal.OperatorConfiguration;
import com.ibm.streamsx.metrics.internal.TupleContainer;

/**
 * A source operator that does not receive any input streams and produces new tuples. 
 * The method <code>produceTuples</code> is called to begin submitting tuples.
 * <P>
 * For a source operator, the following event methods from the Operator interface can be called:
 * </p>
 * <ul>
 * <li><code>initialize()</code> to perform operator initialization</li>
 * <li>allPortsReady() notification indicates the operator's ports are ready to process and submit tuples</li> 
 * <li>shutdown() to shutdown the operator. A shutdown request may occur at any time, 
 * such as a request to stop a PE or cancel a job. 
 * Thus the shutdown() may occur while the operator is processing tuples, punctuation marks, 
 * or even during port ready notification.</li>
 * </ul>
 * <p>With the exception of operator initialization, all the other events may occur concurrently with each other, 
 * which lead to these methods being called concurrently by different threads.</p> 
 */
@PrimitiveOperator(
		name="MemoryMetricsSource",
		namespace="com.ibm.streamsx.metrics",
		description=MemoryMetricsSource.DESC_OPERATOR
		)
@OutputPorts({
	@OutputPortSet(
			cardinality=1,
			optional=false,
			windowPunctuationOutputMode=WindowPunctuationOutputMode.Generating,
			description=MemoryMetricsSource.DESC_OUTPUT_PORT
			)
})
@Libraries({
	// As described here:
	// http://www.ibm.com/support/knowledgecenter/en/SSCRJU_4.2.0/com.ibm.streams.dev.doc/doc/jmxapi-start.html
	// Environment variables (@...@) are evaluated during compile-time and must
	// be identical in the run-time environment.
	"@STREAMS_INSTALL@/lib/com.ibm.streams.management.jmxmp.jar",
	"@STREAMS_INSTALL@/lib/com.ibm.streams.management.mx.jar",
	"@STREAMS_INSTALL@/ext/lib/jmxremote_optional.jar"
	})
public class MemoryMetricsSource extends AbstractOperator {

	// ------------------------------------------------------------------------
	// Documentation.
	// Attention: To add a newline, use \\n instead of \n.
	// ------------------------------------------------------------------------
	
	static final String DESC_OPERATOR = 
			"The MemoryMetricsSource operator uses the "
			+ "[http://www.ibm.com/support/knowledgecenter/SSCRJU_4.2.0/com.ibm.streams.ref.doc/doc/jmxapi.html|JMX] "
			+ "API to retrieve metrics from one or more jobs, and provides "
			+ "metric changes as tuple stream.\\n"
			+ "\\n"
			+ "As an application developer, you provide the so-called filter "
			+ "document. The filter document specifies patterns for domain, "
			+ "instance, job, operator, and metric names. It also specifies "
			+ "which name patterns are related, for example: For a domain X "
			+ "monitor all instances, whereas in each instance only jobs with "
			+ "a Y in their names shall be evaluated. For another domain Z, "
			+ "only jobs with a name ending with XYZ, are monitored, etc.\\n"
			+ "\\n"
			+ "If the MetricsSource evaluates whether, for example, a custom "
			+ "metric of an operator shall be retrieved periodically, the name "
			+ "patterns are applied. A custom metric is uniquely identified "
			+ "with the domain, instance, job, operator, and metric name. All "
			+ "these parts must match to the corresponding set of related name "
			+ "patterns.\\n"
			+ "\\n"
			+ "Per default, the MetricsSource operator monitors neither any "
			+ "domain, nor any instances, nor job, nor any other Streams job-"
			+ "related object. Only those objects (and their parents) that "
			+ "match the specified filters, are monitored.\\n"
			+ "\\n"
			+ "The MetricsSource operator monitors filter-matching domains, "
			+ "instances, and jobs that are running while the application that "
			+ "uses the MetricsSource operator, starts. Furthermore, the "
			+ "operator gets notifications for created and deleted instances, "
			+ "and submitted and cancelled jobs. Thererfore, the operator can "
			+ "retrieve metrics from filter-matching jobs that are submitted "
			+ "in the future.\\n"
			+ "\\n"
			+ "+ Filter document\\n"
			+ "\\n"
			+ "The filter document specifies patterns for domain, instance, "
			+ "job, operator, and metric names, and their relations.\\n"
			+ "\\n"
			+ "The filter document is a JSON-encoded text file that is "
			+ "configured with the **filterDocument** parameter.\\n"
			+ "\\n"
			;
	
	protected static final String DESC_OUTPUT_PORT = 
			"The MetricsSource operator emits a metric tuple to this "
			+ "output port for each metric, for which the operator "
			+ "identifies a changed value. You can use the "
			+ "[type:com.ibm.streamsx.metrics::Notification_t|Notification_t] "
			+ "tuple type, or any subset of the attributes specified for this "
			+ "type. After each scan cycle, the operator emits a WindowMarker "
			+ "to this port."
			;
	
	private static final String DESC_PARAM_CONNECTION_URL = 
			"Specifies the connection URL as returned by the `streamtool "
			+ "getjmxconnect` command.";
	
	private static final String DESC_PARAM_USER = 
			"Specifies the user that is required for the JMX connection.";
	
	private static final String DESC_PARAM_PASSWORD = 
			"Specifies the password that is required for the JMX connection.";
	
	private static final String DESC_PARAM_DOMAIN = 
			"Specifies the domain that is monitored.";
	
	private static final String DESC_PARAM_INSTANCE = 
			"Specifies the instance that is monitored.";
	
	private static final String DESC_PARAM_RETRY_PERIOD = 
			"Specifies the period after which a failed JMX connect is retried. "
			+ "The default is 10.0 seconds.";
	
	private static final String DESC_PARAM_RETRY_COUNT = 
			"Specifies the retry count for failed JMX connects. The default is "
			+ "-1, which means infinite retries.";
	
	private static final String DESC_PARAM_SCAN_PERIOD = 
			"Specifies the period after which a new metrics scan is "
			+ "initiated. The default is 5.0 seconds.";
	
	// ------------------------------------------------------------------------
	// Implementation.
	// ------------------------------------------------------------------------
	
	/**
	 * Thread for calling <code>produceTuples()</code> to produce tuples 
	 */
	private Thread _processThread;

	/**
	 * Logger for tracing.
	 */
	private static Logger _trace = Logger.getLogger(MemoryMetricsSource.class.getName());
	
	private OperatorConfiguration _operatorConfiguration = new OperatorConfiguration();
	
	private String _domainName = null;
	
	private InstanceMXBean _instance = null;
	
	private String _instanceName = null;
	
	private List<JobMXBean> _jobs = new ArrayList<JobMXBean>();
	
	private List<PeMXBean> _pes = new ArrayList<PeMXBean>();
	
	private Map<BigInteger /*peId*/, Long> _capturedMetrics = new HashMap<BigInteger, Long>();
	
	@Parameter(
			optional=false,
			description=MemoryMetricsSource.DESC_PARAM_CONNECTION_URL
			)
	public void setConnectionURL(String connectionURL) {
		_operatorConfiguration.set_connectionURL(connectionURL);
	}

	@Parameter(
			optional=false,
			description=MemoryMetricsSource.DESC_PARAM_USER
			)
	public void setUser(String user) {
		_operatorConfiguration.set_user(user);
	}

	@Parameter(
			optional=false,
			description=MemoryMetricsSource.DESC_PARAM_PASSWORD
			)
	public void setPassword(String password) {
		_operatorConfiguration.set_password(password);
	}

	@Parameter(
			optional=false,
			description=MemoryMetricsSource.DESC_PARAM_DOMAIN
			)
	public void setDomain(String domain) {
		_operatorConfiguration.set_domain(domain);
	}
	
	@Parameter(
			optional=false,
			description=MemoryMetricsSource.DESC_PARAM_INSTANCE
			)
	public void setInstance(String instance) {
		_instanceName = instance;
	}

	@Parameter(
			optional=true,
			description=MemoryMetricsSource.DESC_PARAM_RETRY_PERIOD
			)
	public void setRetryPeriod(double retryPeriod) {
		_operatorConfiguration.set_retryPeriod(retryPeriod);
	}

	@Parameter(
			optional=true,
			description=MemoryMetricsSource.DESC_PARAM_RETRY_COUNT
			)
	public void setRetryCount(int retryCount) {
		_operatorConfiguration.set_retryCount(retryCount);
	}

	@Parameter(
			optional=true,
			description=MemoryMetricsSource.DESC_PARAM_SCAN_PERIOD
			)
	public void setScanPeriod(Double scanPeriod) {
		_operatorConfiguration.set_scanPeriod(scanPeriod);
	}

	/**
	 * Initialize this operator. Called once before any tuples are processed.
	 * @param context OperatorContext for this operator.
	 * @throws Exception Operator failure, will cause the enclosing PE to terminate.
	 */
	@Override
	public synchronized void initialize(OperatorContext context)
			throws Exception {
		// Must call super.initialize(context) to correctly setup an operator.
		super.initialize(context);
		Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " initializing in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );

		/*
		 * Establish connections or resources to communicate an external system
		 * or data store. The configuration information for this comes from
		 * parameters supplied to the operator invocation, or external
		 * configuration files or a combination of the two. 
		 */
		
		/*
		 * Prepare the JMX environment settings.
		 */
		HashMap<String, Object> env = new HashMap<String, Object>();
		String [] credentials = { _operatorConfiguration.get_user(), _operatorConfiguration.get_password() };
		env.put("jmx.remote.credentials", credentials);
		env.put("jmx.remote.protocol.provider.pkgs", "com.ibm.streams.management");

		/*
		 * Setup the JMX connector and MBean connection.
		 */
		_operatorConfiguration.set_jmxConnector(JMXConnectorFactory.connect(new JMXServiceURL(_operatorConfiguration.get_connectionURL()), env));
		_operatorConfiguration.set_mbeanServerConnection(_operatorConfiguration.get_jmxConnector().getMBeanServerConnection());

		/*
		 * Evaluate the output schema once.
		 * Create and submit tuples to the output port for each changed metric.
		 */
		final StreamingOutput<OutputTuple> port = getOutput(0);
		_operatorConfiguration.set_tupleContainer(new TupleContainer(port));
		
		_domainName = _operatorConfiguration.get_domain();
		
		// Create InstanceMXBean for getting JobMXBeans.
		try {
			_instance = JMX.newMXBeanProxy(_operatorConfiguration.get_mbeanServerConnection(),
											ObjectNameBuilder.instance(_domainName, _instanceName),
											InstanceMXBean.class, true);
		} catch (Exception e) {
			Logger.getLogger(this.getClass()).error("InstanceMXBean connect error", e);
		}

		/*
		 * Create the thread for producing tuples. 
		 * The thread is created at initialize time but started.
		 * The thread will be started by allPortsReady().
		 */
		_processThread = getOperatorContext().getThreadFactory().newThread(
				new Runnable() {

					@Override
					public void run() {
						try {
							produceTuples();
						} catch (Exception e) {
							Logger.getLogger(this.getClass()).error("Operator error", e);
						}                    
					}

				});

		/*
		 * Set the thread not to be a daemon to ensure that the SPL runtime
		 * will wait for the thread to complete before determining the
		 * operator is complete.
		 */
		_processThread.setDaemon(false);
	}

	/**
	 * Notification that initialization is complete and all input and output ports 
	 * are connected and ready to receive and submit tuples.
	 * @throws Exception Operator failure, will cause the enclosing PE to terminate.
	 */
	@Override
	public synchronized void allPortsReady() throws Exception {
		OperatorContext context = getOperatorContext();
		Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " all ports are ready in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
		// Start a thread for producing tuples because operator 
		// implementations must not block and must return control to the caller.
		_processThread.start();
	}

	/**
	 * Submit new tuples to the output stream
	 * @throws Exception if an error occurs while submitting a tuple
	 */
	private void produceTuples() throws Exception  {
		boolean quit = false;
		while(!quit) {
			// Retrieve all jobs in instance for gathering PEs.
			_jobs.clear();
			for (BigInteger jobId : _instance.getJobs()) {
				_jobs.add(JMX.newMXBeanProxy(_operatorConfiguration.get_mbeanServerConnection(),
						ObjectNameBuilder.job(_domainName, _instanceName, jobId),
						JobMXBean.class, true));
			}
			
			// Retrieve all PEs in each job for gathering/monitoring metrics.
			_pes.clear();
			for (JobMXBean job : _jobs) {
				for (BigInteger peId : job.getPes()) {
					_pes.add(JMX.newMXBeanProxy(_operatorConfiguration.get_mbeanServerConnection(),
							ObjectNameBuilder.pe(_domainName, _instanceName, peId),
							PeMXBean.class, true));
				}
			}

			// Capture and submit metrics.
			if(!_pes.isEmpty()) {
				captureAndSubmitChangedMetrics();
			}

			Thread.sleep(Double.valueOf(_operatorConfiguration.get_scanPeriod() * 1000.0).longValue());
		}

		/*
		 * When finished, submit a final punctuation:
		 */
		_operatorConfiguration.get_tupleContainer().punctuate(Punctuation.FINAL_MARKER);
	}

	/**
	 * Shutdown this operator, which will interrupt the thread
	 * executing the <code>produceTuples()</code> method.
	 * @throws Exception Operator failure, will cause the enclosing PE to terminate.
	 */
	public synchronized void shutdown() throws Exception {
		if (_processThread != null) {
			_processThread.interrupt();
			_processThread = null;
		}
		OperatorContext context = getOperatorContext();
		Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " shutting down in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );

		// Close connections or release resources related to any external system or data store.
		
		if (_operatorConfiguration.get_jmxConnector() != null) {
			_operatorConfiguration.get_jmxConnector().close();
		}

		// Must call super.shutdown()
		super.shutdown();
	}
	
	protected void checkAndSubmitMetric(Metric metric, BigInteger peId) throws Exception {
		_trace.error("pe" + peId + " enter.");
		if(_capturedMetrics.containsKey(peId)) {
			// If metric is not new, only submit tuple if metric is new.
			long lastCapturedMemory = _capturedMetrics.get(peId);
			_trace.error("oldval:" + String.valueOf(lastCapturedMemory) + ",newval:" + String.valueOf(metric.getValue()));
			if (lastCapturedMemory != metric.getValue()) {
				// Store metric to check for changes later.
				_capturedMetrics.put(peId, metric.getValue());
				
				// Submit metric to output port.
				_operatorConfiguration.get_tupleContainer().setDomainName(_domainName);
				_operatorConfiguration.get_tupleContainer().setInstanceName(_instanceName);
				//_operatorConfiguration.get_tupleContainer().setJobId(jobId);
				_operatorConfiguration.get_tupleContainer().setPeId(peId);
				_operatorConfiguration.get_tupleContainer().setMetricName(metric.getName());
				_operatorConfiguration.get_tupleContainer().setMetricValue(metric.getValue());
				_operatorConfiguration.get_tupleContainer().setLastTimeRetrieved(metric.getLastTimeRetrieved());
				_operatorConfiguration.get_tupleContainer().submit();
				
				_trace.error("pe" + peId + " submitted.");

				/*
				 * Emit a window marker after each scan cycle.
				 */
				_operatorConfiguration.get_tupleContainer().punctuate(Punctuation.WINDOW_MARKER);
			}
		} else {
			// Store metric to check for changes later.
			_capturedMetrics.put(peId, metric.getValue());
			
			// Submit metric to output port.
			_operatorConfiguration.get_tupleContainer().setDomainName(_domainName);
			_operatorConfiguration.get_tupleContainer().setInstanceName(_instanceName);
			//_operatorConfiguration.get_tupleContainer().setJobId(jobId);
			_operatorConfiguration.get_tupleContainer().setPeId(peId);
			_operatorConfiguration.get_tupleContainer().setMetricName(metric.getName());
			_operatorConfiguration.get_tupleContainer().setMetricValue(metric.getValue());
			_operatorConfiguration.get_tupleContainer().setLastTimeRetrieved(metric.getLastTimeRetrieved());
			_operatorConfiguration.get_tupleContainer().submit();

			_trace.error("pe" + peId + " submitted.");
			/*
			 * Emit a window marker after each scan cycle.
			 */
			_operatorConfiguration.get_tupleContainer().punctuate(Punctuation.WINDOW_MARKER);
		}
	}
	
	/**
	 * Retrieve metrics, depending on the registration mode evaluate which
	 * metrics are relevant, and submit tuples for changed metric values.
	 * 
	 * @throws Exception
	 * Throws Exception if submitting the tuple fails. 
	 */
	protected void captureAndSubmitChangedMetrics() throws Exception {
		// Sum up memory metrics for all PEs in instance.
		// long sumMemoryConsumption = 0;
		long sumResidentMemoryConsumption = 0;
		for (PeMXBean pe : _pes) {
			Set<Metric> metrics = pe.retrieveMetrics(true);
			for (Metric metric : metrics) {
				switch(metric.getName()) {
//					case "nMemoryConsumption":
//						//sumMemoryConsumption += metric.getValue();
//						Metric nMemoryConsumptionMetric = createNewMetric("nMemoryConsumption", metric.getValue());
//						checkAndSubmitMetric(nMemoryConsumptionMetric, pe.getId());
//						break;
					case "nResidentMemoryConsumption":
						sumResidentMemoryConsumption += metric.getValue();
						Metric nResidentMemoryConsumptionMetric = createNewMetric("nResidentMemoryConsumption", metric.getValue());
						checkAndSubmitMetric(nResidentMemoryConsumptionMetric, pe.getId());
						break;
//					default:
//						_trace.error("No cases for metrics match: " + metric.getName());
				}
			}
		}
		
		// Construct custom metrics and submit.
//		Metric nMemoryConsumptionMetric = createNewMetric("nMemoryConsumption", sumMemoryConsumption);
//		checkAndSubmitMetric(nMemoryConsumptionMetric);
		
		Metric nResidentMemoryConsumptionMetric = createNewMetric("nResidentMemoryConsumptionSum", sumResidentMemoryConsumption);
		//checkAndSubmitAvgMetric(nResidentMemoryConsumptionMetric);
	}

	private Metric createNewMetric(String name, long value) {
		Metric constructedMetric = new Metric() {
		
			@Override
			public String getName() {
				return name;
			}
			
			@Override
			public Type getMetricType() {
				return null;
			}
			
			@Override
			public Kind getMetricKind() {
				return null;
			}
			
			@Override
			public String getDescription() {
				return null;
			}
			
			@Override
			public long getValue() {
				return value;
			}
			
			@Override
			public long getLastTimeRetrieved() {
				return System.currentTimeMillis();
			}
		};
		
		return constructedMetric;
	}
}
